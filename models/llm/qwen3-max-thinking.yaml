model: Qwen3-Max-Thinking
label:
  en_US: Qwen3-Max-Thinking
  zh_Hans: Qwen3-Max-Thinking
model_type: llm
features:
  - multi-tool-call
  - stream-tool-call
  - tool-call
model_properties:
  mode: chat
  context_size: 262144
parameter_rules:
- name: max_tokens
  use_template: max_tokens
  type: int
  min: 1
  max: 8192
  default: 2048
- name: temperature
  use_template: temperature
  type: float
  min: 0.0
  max: 2.0
- name: top_p
  use_template: top_p
  type: float
  min: 0.0
  max: 1.0
- name: top_k
  use_template: top_k
  type: int
- name: presence_penalty
  use_template: presence_penalty
  type: float
  min: -2.0
  max: 2.0
- name: stream
  label:
    en_US: Stream
    zh_Hans: 流式输出
  type: boolean
  default: false
  required: false
  help:
    en_US: Whether to stream the response. If true, the response will be streamed back as it is generated.
    zh_Hans: 是否流式返回响应。如果为 true，响应将在生成时流式返回。
- name: modalities
  label:
    en_US: Modalities
    zh_Hans: 模态
  type: string
  required: false
  options:
  - text
  help:
    en_US: The type of output the model should generate. Most models can generate text, text is the default type
    zh_Hans: 希望模型生成的输出类型。大多数模型都可以生成文本，文本是默认类型
- name: response_format
  use_template: response_format
  type: string
  options:
  - text
  - json_object
- name: enable_thinking
  label:
    en_US: Enable Thinking
    zh_Hans: 启用思考模式
  type: boolean
  default: true
  required: false
  help:
    en_US: Whether to enable thinking mode for models that support it
    zh_Hans: 是否为支持思考模式的模型启用思考功能（部分模型可能不支持思考）
- name: sort
  label:
    en_US: Sort By
    zh_Hans: 智能路由策略
  type: string
  default: none
  required: false
  options:
  - input_price
  - output_price
  - latency
  - throughput
  - input_length
  - none
  help:
    en_US: 'Sort providers by: input_price, output_price, throughput, latency, or context_length'
    zh_Hans: 按以下方式排序供应商：input_price（输入价格）、output_price（输出价格）、throughput（吞吐量）、latency（延迟）或 context_length（上下文长度）
